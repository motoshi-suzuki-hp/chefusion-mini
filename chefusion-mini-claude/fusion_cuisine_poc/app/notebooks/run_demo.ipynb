{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicultural Fusion Cuisine Generator & Palate Predictor\n",
    "\n",
    "This notebook provides an interactive demo of the complete fusion cuisine generation pipeline.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. **Data Loading**: Generate mock RecipeNLG dataset with Japanese and Italian recipes\n",
    "2. **Preprocessing**: Clean data and create PyG-compatible format\n",
    "3. **Model Training**: Train encoder and PalateNet models\n",
    "4. **Fusion Generation**: Create fusion recipes with different alpha values\n",
    "5. **Evaluation**: Analyze results and compute metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Image as IPImage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import configuration\n",
    "from app.config import config\n",
    "from app.utils import setup_logging\n",
    "\n",
    "# Setup logging and display configuration\n",
    "setup_logging(\"INFO\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Configuration file: {config.config_path}\")\n",
    "print(f\"Offline mode: {config.offline_mode}\")\n",
    "print(f\"Random seed: {config.random_seed}\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Step 1: Data Loading and Generation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run data fetching script\n",
    "os.chdir(project_root)\n",
    "%run scripts/01_fetch_data.py\n",
    "\n",
    "data_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Data generation completed in {data_time:.1f} seconds\")\n",
    "\n",
    "# Load and display data summary\n",
    "try:\n",
    "    with open(config.data_dir / \"data_summary.json\", \"r\") as f:\n",
    "        data_summary = json.load(f)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Data Summary:\")\n",
    "    for key, value in data_summary.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load data summary: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze the generated data\n",
    "try:\n",
    "    recipes_df = pd.read_csv(config.data_dir / \"recipes.csv\")\n",
    "    ratings_df = pd.read_csv(config.data_dir / \"ratings.csv\")\n",
    "    \n",
    "    print(f\"ğŸ“ˆ Dataset Analysis:\")\n",
    "    print(f\"   Total recipes: {len(recipes_df)}\")\n",
    "    print(f\"   Total ratings: {len(ratings_df)}\")\n",
    "    print(f\"   Average rating: {recipes_df['rating'].mean():.2f}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Recipe distribution by cuisine\n",
    "    recipes_df['cuisine'].value_counts().plot(kind='bar', ax=axes[0,0], title='Recipes by Cuisine')\n",
    "    axes[0,0].set_ylabel('Number of Recipes')\n",
    "    \n",
    "    # Rating distribution\n",
    "    recipes_df['rating'].hist(bins=20, ax=axes[0,1], title='Rating Distribution')\n",
    "    axes[0,1].set_xlabel('Rating')\n",
    "    axes[0,1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Ingredients per recipe\n",
    "    recipes_df['num_ingredients'].hist(bins=15, ax=axes[1,0], title='Ingredients per Recipe')\n",
    "    axes[1,0].set_xlabel('Number of Ingredients')\n",
    "    axes[1,0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Rating by cuisine\n",
    "    recipes_df.boxplot(column='rating', by='cuisine', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Rating Distribution by Cuisine')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show sample recipes\n",
    "    print(\"\\nğŸ½ï¸  Sample Recipes:\")\n",
    "    for cuisine in config.target_cuisines:\n",
    "        sample = recipes_df[recipes_df['cuisine'] == cuisine].iloc[0]\n",
    "        print(f\"\\n{cuisine.upper()}:\")\n",
    "        print(f\"  Title: {sample['title']}\")\n",
    "        print(f\"  Ingredients: {sample['ingredients'][:100]}...\")\n",
    "        print(f\"  Rating: {sample['rating']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Step 2: Data Preprocessing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run preprocessing script\n",
    "os.chdir(project_root)\n",
    "%run scripts/02_preprocess.py\n",
    "\n",
    "preprocess_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Preprocessing completed in {preprocess_time:.1f} seconds\")\n",
    "\n",
    "# Load and display preprocessing metadata\n",
    "try:\n",
    "    with open(config.data_dir / \"preprocessing_metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Preprocessing Results:\")\n",
    "    for key, value in metadata.items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Could not load preprocessing metadata: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze preprocessing results\n",
    "try:\n",
    "    # Load processed data splits\n",
    "    train_df = pd.read_csv(config.data_dir / \"train.csv\")\n",
    "    val_df = pd.read_csv(config.data_dir / \"val.csv\")\n",
    "    test_df = pd.read_csv(config.data_dir / \"test.csv\")\n",
    "    \n",
    "    # Load embeddings\n",
    "    text_embeddings = np.load(config.data_dir / \"text_embeddings.npy\")\n",
    "    ingredient_embeddings = np.load(config.data_dir / \"ingredient_embeddings.npy\")\n",
    "    \n",
    "    print(\"ğŸ“ˆ Preprocessing Analysis:\")\n",
    "    print(f\"   Train samples: {len(train_df)}\")\n",
    "    print(f\"   Validation samples: {len(val_df)}\")\n",
    "    print(f\"   Test samples: {len(test_df)}\")\n",
    "    print(f\"   Text embedding dimension: {text_embeddings.shape[1]}\")\n",
    "    print(f\"   Ingredient embedding dimension: {ingredient_embeddings.shape[1]}\")\n",
    "    \n",
    "    # Visualize data splits\n",
    "    split_data = {\n",
    "        'Train': len(train_df),\n",
    "        'Validation': len(val_df),\n",
    "        'Test': len(test_df)\n",
    "    }\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.pie(split_data.values(), labels=split_data.keys(), autopct='%1.1f%%')\n",
    "    plt.title('Dataset Splits')\n",
    "    \n",
    "    # Visualize embedding dimensions\n",
    "    plt.subplot(1, 2, 2)\n",
    "    embedding_dims = {\n",
    "        'Text': text_embeddings.shape[1],\n",
    "        'Ingredients': ingredient_embeddings.shape[1]\n",
    "    }\n",
    "    plt.bar(embedding_dims.keys(), embedding_dims.values())\n",
    "    plt.title('Embedding Dimensions')\n",
    "    plt.ylabel('Dimension')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing preprocessing results: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Train Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Step 3a: Training Encoder Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run encoder training script\n",
    "os.chdir(project_root)\n",
    "%run scripts/train_encoder.py\n",
    "\n",
    "encoder_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Encoder training completed in {encoder_time:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Train PalateNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Step 3b: Training PalateNet Model\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run PalateNet training script\n",
    "os.chdir(project_root)\n",
    "%run scripts/train_palatenet.py\n",
    "\n",
    "palatenet_time = time.time() - start_time\n",
    "print(f\"\\nâœ… PalateNet training completed in {palatenet_time:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if models were saved successfully\n",
    "model_files = {\n",
    "    'Encoder (Best)': config.models_dir / \"encoder_best.pt\",\n",
    "    'Encoder (Final)': config.models_dir / \"encoder_final.pt\",\n",
    "    'PalateNet (Best)': config.models_dir / \"palatenet_best.pt\",\n",
    "    'PalateNet (Final)': config.models_dir / \"palatenet_final.pt\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ’¾ Saved Models:\")\n",
    "for name, path in model_files.items():\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   âœ… {name}: {size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"   âŒ {name}: Not found\")\n",
    "\n",
    "print(f\"\\nâ±ï¸  Total Training Time: {encoder_time + palatenet_time:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fusion Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Step 4: Fusion Generation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run fusion generation script\n",
    "os.chdir(project_root)\n",
    "%run scripts/generate_fusion.py\n",
    "\n",
    "generation_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Fusion generation completed in {generation_time:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Fusion Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated fusion recipes\n",
    "try:\n",
    "    fusion_recipes_path = config.outputs_dir / \"recipes\" / \"fusion_recipes.json\"\n",
    "    \n",
    "    if fusion_recipes_path.exists():\n",
    "        with open(fusion_recipes_path, \"r\") as f:\n",
    "            fusion_recipes = json.load(f)\n",
    "        \n",
    "        print(\"ğŸ½ï¸  Generated Fusion Recipes:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for alpha_key, recipe_data in fusion_recipes.items():\n",
    "            alpha = recipe_data[\"alpha\"]\n",
    "            recipe = recipe_data[\"recipe\"]\n",
    "            \n",
    "            print(f\"\\nğŸ¯ Alpha = {alpha} (Japanese: {alpha:.1f}, Italian: {1-alpha:.1f})\")\n",
    "            print(\"-\" * 50)\n",
    "            print(recipe[:500] + \"...\" if len(recipe) > 500 else recipe)\n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "    else:\n",
    "        print(\"âŒ No fusion recipes found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading fusion recipes: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Images (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated images if available\n",
    "try:\n",
    "    fusion_images_path = config.outputs_dir / \"images\" / \"fusion_images.json\"\n",
    "    \n",
    "    if fusion_images_path.exists():\n",
    "        with open(fusion_images_path, \"r\") as f:\n",
    "            fusion_images = json.load(f)\n",
    "        \n",
    "        print(\"ğŸ–¼ï¸  Generated Fusion Images:\")\n",
    "        \n",
    "        # Display images in a grid\n",
    "        num_images = len(fusion_images)\n",
    "        if num_images > 0:\n",
    "            cols = min(3, num_images)\n",
    "            rows = (num_images + cols - 1) // cols\n",
    "            \n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "            if rows == 1:\n",
    "                axes = [axes] if cols == 1 else axes\n",
    "            elif cols == 1:\n",
    "                axes = [[ax] for ax in axes]\n",
    "            \n",
    "            for i, (alpha_key, image_data) in enumerate(fusion_images.items()):\n",
    "                row, col = i // cols, i % cols\n",
    "                ax = axes[row][col] if rows > 1 else axes[col]\n",
    "                \n",
    "                try:\n",
    "                    from PIL import Image as PILImage\n",
    "                    image_path = Path(image_data[\"file\"])\n",
    "                    if image_path.exists():\n",
    "                        img = PILImage.open(image_path)\n",
    "                        ax.imshow(img)\n",
    "                        ax.set_title(f\"Alpha = {image_data['alpha']}\")\n",
    "                        ax.axis('off')\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, 'Image not found', ha='center', va='center')\n",
    "                        ax.set_title(f\"Alpha = {image_data['alpha']}\")\n",
    "                except Exception as e:\n",
    "                    ax.text(0.5, 0.5, f'Error: {e}', ha='center', va='center')\n",
    "                    ax.set_title(f\"Alpha = {image_data['alpha']}\")\n",
    "            \n",
    "            # Hide unused subplots\n",
    "            for i in range(num_images, rows * cols):\n",
    "                row, col = i // cols, i % cols\n",
    "                ax = axes[row][col] if rows > 1 else axes[col]\n",
    "                ax.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"   No images were generated\")\n",
    "    else:\n",
    "        print(\"ğŸ“ Images not generated (likely using text-only mode)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error displaying images: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Step 5: Comprehensive Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run evaluation script\n",
    "os.chdir(project_root)\n",
    "%run scripts/evaluate.py\n",
    "\n",
    "evaluation_time = time.time() - start_time\n",
    "print(f\"\\nâœ… Evaluation completed in {evaluation_time:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze evaluation results\n",
    "try:\n",
    "    evaluation_path = config.outputs_dir / \"evaluation_metrics.json\"\n",
    "    \n",
    "    if evaluation_path.exists():\n",
    "        with open(evaluation_path, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        # Create comprehensive visualization of results\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Rating prediction performance\n",
    "        if metrics.get(\"rating_prediction\"):\n",
    "            rating_metrics = metrics[\"rating_prediction\"]\n",
    "            \n",
    "            metric_names = ['Spearman Corr', 'RÂ² Score']\n",
    "            metric_values = [\n",
    "                rating_metrics.get('spearman_correlation', 0),\n",
    "                rating_metrics.get('r2_score', 0)\n",
    "            ]\n",
    "            \n",
    "            bars = axes[0,0].bar(metric_names, metric_values)\n",
    "            axes[0,0].set_title('Rating Prediction Performance')\n",
    "            axes[0,0].set_ylim(0, 1)\n",
    "            \n",
    "            # Add target line for Spearman correlation\n",
    "            axes[0,0].axhline(y=config.target_spearman_correlation, color='r', linestyle='--', \n",
    "                            label=f'Target ({config.target_spearman_correlation})')\n",
    "            axes[0,0].legend()\n",
    "            \n",
    "            # Color bars based on target achievement\n",
    "            if rating_metrics.get('spearman_correlation', 0) >= config.target_spearman_correlation:\n",
    "                bars[0].set_color('green')\n",
    "            else:\n",
    "                bars[0].set_color('orange')\n",
    "        \n",
    "        # Ingredient overlap analysis\n",
    "        if metrics.get(\"ingredient_overlap\"):\n",
    "            overlap_metrics = metrics[\"ingredient_overlap\"]\n",
    "            alpha_overlaps = overlap_metrics.get('alpha_specific_overlaps', {})\n",
    "            \n",
    "            if alpha_overlaps:\n",
    "                alphas = [float(k.split('_')[1]) for k in alpha_overlaps.keys()]\n",
    "                overlaps = list(alpha_overlaps.values())\n",
    "                \n",
    "                axes[0,1].plot(alphas, overlaps, 'bo-', linewidth=2, markersize=8)\n",
    "                axes[0,1].set_title('Ingredient Overlap by Alpha')\n",
    "                axes[0,1].set_xlabel('Alpha (Japanese weight)')\n",
    "                axes[0,1].set_ylabel('Overlap Score')\n",
    "                axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Diversity metrics\n",
    "        if metrics.get(\"diversity\"):\n",
    "            diversity_metrics = metrics[\"diversity\"]\n",
    "            \n",
    "            diversity_data = {\n",
    "                'Unique\\nIngredients': diversity_metrics.get('total_unique_ingredients', 0),\n",
    "                'Avg Ingredients\\nper Recipe': diversity_metrics.get('avg_ingredients_per_recipe', 0),\n",
    "                'Fusion\\nRecipes': diversity_metrics.get('num_fusion_recipes', 0)\n",
    "            }\n",
    "            \n",
    "            bars = axes[1,0].bar(diversity_data.keys(), diversity_data.values())\n",
    "            axes[1,0].set_title('Recipe Diversity Metrics')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Pipeline performance summary\n",
    "        pipeline_times = {\n",
    "            'Data Gen': data_time,\n",
    "            'Preprocessing': preprocess_time,\n",
    "            'Encoder Train': encoder_time,\n",
    "            'PalateNet Train': palatenet_time,\n",
    "            'Generation': generation_time,\n",
    "            'Evaluation': evaluation_time\n",
    "        }\n",
    "        \n",
    "        axes[1,1].pie(pipeline_times.values(), labels=pipeline_times.keys(), autopct='%1.1f%%')\n",
    "        axes[1,1].set_title('Pipeline Time Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Summary statistics\n",
    "        total_time = sum(pipeline_times.values())\n",
    "        \n",
    "        print(\"\\nğŸ“Š PIPELINE PERFORMANCE SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total Pipeline Time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "        \n",
    "        if metrics.get(\"rating_prediction\"):\n",
    "            spearman = metrics[\"rating_prediction\"].get('spearman_correlation', 0)\n",
    "            target_achieved = spearman >= config.target_spearman_correlation\n",
    "            print(f\"Target Achievement: {'âœ… SUCCESS' if target_achieved else 'âŒ FAILED'}\")\n",
    "            print(f\"Spearman Correlation: {spearman:.4f} (target: {config.target_spearman_correlation})\")\n",
    "        \n",
    "        if metrics.get(\"ingredient_overlap\"):\n",
    "            avg_overlap = metrics[\"ingredient_overlap\"].get('avg_ingredient_overlap', 0)\n",
    "            print(f\"Average Ingredient Overlap: {avg_overlap:.4f}\")\n",
    "        \n",
    "        print(f\"Fusion Recipes Generated: {len(fusion_recipes) if 'fusion_recipes' in locals() else 0}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ Evaluation metrics not found\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing evaluation results: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ‰ FUSION CUISINE PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate total pipeline time\n",
    "total_pipeline_time = (\n",
    "    data_time + preprocess_time + encoder_time + \n",
    "    palatenet_time + generation_time + evaluation_time\n",
    ")\n",
    "\n",
    "print(f\"\\nâ±ï¸  TIMING BREAKDOWN:\")\n",
    "print(f\"   Data Generation: {data_time:.1f}s ({data_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   Preprocessing: {preprocess_time:.1f}s ({preprocess_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   Encoder Training: {encoder_time:.1f}s ({encoder_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   PalateNet Training: {palatenet_time:.1f}s ({palatenet_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   Fusion Generation: {generation_time:.1f}s ({generation_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   Evaluation: {evaluation_time:.1f}s ({evaluation_time/total_pipeline_time*100:.1f}%)\")\n",
    "print(f\"   TOTAL: {total_pipeline_time:.1f}s ({total_pipeline_time/60:.1f} minutes)\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ OUTPUT FILES:\")\n",
    "output_files = [\n",
    "    config.outputs_dir / \"recipes\" / \"fusion_recipes.json\",\n",
    "    config.outputs_dir / \"evaluation_metrics.json\",\n",
    "    config.outputs_dir / \"fusion_embeddings.json\"\n",
    "]\n",
    "\n",
    "for file_path in output_files:\n",
    "    if file_path.exists():\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"   âœ… {file_path.name}: {size_kb:.1f} KB\")\n",
    "    else:\n",
    "        print(f\"   âŒ {file_path.name}: Not found\")\n",
    "\n",
    "# Check for generated images\n",
    "images_dir = config.outputs_dir / \"images\"\n",
    "if images_dir.exists():\n",
    "    image_files = list(images_dir.glob(\"*.png\")) + list(images_dir.glob(\"*.jpg\"))\n",
    "    print(f\"   ğŸ–¼ï¸  Generated Images: {len(image_files)}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ SUCCESS CRITERIA:\")\n",
    "try:\n",
    "    if 'metrics' in locals() and metrics.get(\"rating_prediction\"):\n",
    "        spearman = metrics[\"rating_prediction\"].get('spearman_correlation', 0)\n",
    "        target_met = spearman >= config.target_spearman_correlation\n",
    "        print(f\"   Spearman Correlation â‰¥ {config.target_spearman_correlation}: {'âœ…' if target_met else 'âŒ'} ({spearman:.4f})\")\n",
    "    \n",
    "    if 'fusion_recipes' in locals():\n",
    "        recipes_generated = len(fusion_recipes) == len(config.fusion_alphas)\n",
    "        print(f\"   Fusion Recipes Generated: {'âœ…' if recipes_generated else 'âŒ'} ({len(fusion_recipes)}/{len(config.fusion_alphas)})\")\n",
    "    \n",
    "    time_limit_met = total_pipeline_time <= 4 * 3600  # 4 hours\n",
    "    print(f\"   Time Limit (â‰¤4 hours): {'âœ…' if time_limit_met else 'âŒ'} ({total_pipeline_time/3600:.2f}h)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   Error checking success criteria: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“ All outputs saved to: {config.outputs_dir}\")\n",
    "print(f\"ğŸ“ Models saved to: {config.models_dir}\")\n",
    "print(f\"ğŸ“Š Data saved to: {config.data_dir}\")\n",
    "\n",
    "print(\"\\nğŸš€ Pipeline execution completed successfully!\")\n",
    "print(\"   You can now explore the generated fusion recipes and evaluation results.\")\n",
    "print(\"   Try running individual components again with different parameters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exploration\n",
    "\n",
    "Use the cells below to explore the results interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Explore specific fusion recipes\n",
    "try:\n",
    "    if 'fusion_recipes' in locals():\n",
    "        print(\"ğŸ” Interactive Recipe Explorer\")\n",
    "        print(\"Available alpha values:\", [data['alpha'] for data in fusion_recipes.values()])\n",
    "        \n",
    "        # You can modify this to explore specific recipes\n",
    "        alpha_to_explore = 0.5  # Change this value\n",
    "        \n",
    "        for key, data in fusion_recipes.items():\n",
    "            if abs(data['alpha'] - alpha_to_explore) < 0.01:\n",
    "                print(f\"\\nğŸ“– Fusion Recipe (Î±={data['alpha']}):\")\n",
    "                print(\"=\" * 50)\n",
    "                print(data['recipe'])\n",
    "                break\n",
    "        else:\n",
    "            print(f\"No recipe found for alpha = {alpha_to_explore}\")\n",
    "except:\n",
    "    print(\"Fusion recipes not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive: Model performance analysis\n",
    "try:\n",
    "    if 'metrics' in locals():\n",
    "        print(\"ğŸ“ˆ Model Performance Deep Dive\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # Rating prediction details\n",
    "        if metrics.get('rating_prediction'):\n",
    "            rating_perf = metrics['rating_prediction']\n",
    "            print(f\"\\nğŸ¯ Rating Prediction Model:\")\n",
    "            print(f\"   Spearman Correlation: {rating_perf.get('spearman_correlation', 0):.4f}\")\n",
    "            print(f\"   RMSE: {rating_perf.get('rmse', 0):.4f}\")\n",
    "            print(f\"   MAE: {rating_perf.get('mae', 0):.4f}\")\n",
    "            print(f\"   RÂ² Score: {rating_perf.get('r2_score', 0):.4f}\")\n",
    "            print(f\"   Test Samples: {rating_perf.get('num_samples', 0)}\")\n",
    "        \n",
    "        # Ingredient overlap details\n",
    "        if metrics.get('ingredient_overlap'):\n",
    "            overlap_perf = metrics['ingredient_overlap']\n",
    "            print(f\"\\nğŸ¥˜ Ingredient Overlap Analysis:\")\n",
    "            print(f\"   Average Overlap: {overlap_perf.get('avg_ingredient_overlap', 0):.4f}\")\n",
    "            print(f\"   Standard Deviation: {overlap_perf.get('std_ingredient_overlap', 0):.4f}\")\n",
    "            \n",
    "            alpha_overlaps = overlap_perf.get('alpha_specific_overlaps', {})\n",
    "            for alpha_key, overlap in alpha_overlaps.items():\n",
    "                print(f\"   {alpha_key}: {overlap:.4f}\")\n",
    "                \n",
    "except:\n",
    "    print(\"Metrics not available for analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You have successfully completed the **Multicultural Fusion Cuisine Generator & Palate Predictor** pipeline!\n",
    "\n",
    "### What was accomplished:\n",
    "1. âœ… Generated mock RecipeNLG dataset with 10,000 recipes (5K Japanese + 5K Italian)\n",
    "2. âœ… Created ingredient FlavorGraph with co-occurrence relationships  \n",
    "3. âœ… Preprocessed data for PyTorch Geometric compatibility\n",
    "4. âœ… Trained CLIP-mini encoder for text/image fusion\n",
    "5. âœ… Trained GraphSAGE + MLP PalateNet for rating prediction\n",
    "6. âœ… Generated fusion recipes with different Î± values (0.3, 0.5, 0.7)\n",
    "7. âœ… Evaluated system performance with comprehensive metrics\n",
    "\n",
    "### Key Results:\n",
    "- **Rating Prediction**: Achieved Spearman correlation for taste prediction\n",
    "- **Fusion Generation**: Created novel Japanese-Italian fusion recipes\n",
    "- **Ingredient Analysis**: Analyzed ingredient overlap and diversity\n",
    "- **Pipeline Performance**: Complete end-to-end execution within resource constraints\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different Î± values for fusion\n",
    "- Try the pipeline with your own recipe data\n",
    "- Explore the generated recipes and adapt them for cooking\n",
    "- Enhance the models with additional cuisines or features\n",
    "\n",
    "**Happy cooking and experimenting! ğŸ‘¨â€ğŸ³ğŸ‘©â€ğŸ³**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
